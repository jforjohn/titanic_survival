{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from config_loader import load\n",
    "import argparse\n",
    "import sys\n",
    "import seaborn as sns\n",
    "from MyDataUnderstanding import featureAnalysis\n",
    "from MyPreprocessing import MyPreprocessing\n",
    "import numpy as np\n",
    "from time import time\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from model.models import models_perform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.width', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(path, filenames_type):\n",
    "    '''\n",
    "    features_lst = [\n",
    "        \"Pclass\", \"Survived\", \"Name\", \"Sex\", \"Age\",\n",
    "        \"Sibsp\", \"Parch\", \"Ticket\", \"Fare\", \"Cabin\",\"Embarked\",\n",
    "        \"Boat\",\"Body\",\"Home.dest\"]\n",
    "    '''\n",
    "    if filenames_type == 'train':\n",
    "        filename = 'train'\n",
    "    elif filenames_type == 'test':\n",
    "        filename = 'test'\n",
    "    else:\n",
    "        filename = 'titanicAll'\n",
    "        \n",
    "    df_features = pd.read_csv(path + filename + '.csv',\n",
    "                           sep=',')\n",
    "\n",
    "    if filename not in ['train', 'test']:\n",
    "        # drop unnecessary columns that don't exist in the official data\n",
    "        df_features.drop(['Boat', 'Body', 'Home.dest'],\n",
    "                           axis=1,\n",
    "                           inplace=True)\n",
    "    #labels = df_features['Survived']\n",
    "    #df_features = df_features.drop(['Survived'], axis=1)\n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    \"-c\", \"--config\", default=\"titanic.cfg\",\n",
    "    help=\"specify the location of the clustering config file\"\n",
    ")\n",
    "args, _ = parser.parse_known_args()\n",
    "\n",
    "config_file = args.config\n",
    "config = load(config_file)\n",
    "\n",
    "##\n",
    "verbose = config.get('titanic', 'verbose')\n",
    "path = config.get('titanic', 'path') + '/'\n",
    "file_type = config.get('titanic', 'file_type')\n",
    "\n",
    "filename_type = 'train'\n",
    "if file_type == 'all':\n",
    "    filename_type = 'other'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = getData(path, filename_type)\n",
    "\n",
    "# Preprocessing\n",
    "trainPreprocess = MyPreprocessing(filename_type)\n",
    "\n",
    "## test\n",
    "filename_type = 'test'\n",
    "testData = getData(path, filename_type)\n",
    "# Preprocessing\n",
    "testPreprocess = MyPreprocessing(filename_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1309, 49) (418, 48)\n"
     ]
    }
   ],
   "source": [
    "trainPreprocess.fit(trainData)\n",
    "df_train = trainPreprocess.new_df\n",
    "# the labels \"Survived\"\n",
    "labels = trainPreprocess.labels_\n",
    "\n",
    "testPreprocess.fit(testData)\n",
    "df_test = testPreprocess.new_df\n",
    "labels_test = testPreprocess.labels_\n",
    "\n",
    "# fix missing columns because of NaNs and one hot encoding without dummy_na\n",
    "if df_train.shape[1] != df_test.shape[1]:\n",
    "    missing_cols = set(df_test.columns) - set(df_train.columns)\n",
    "    for col in missing_cols:\n",
    "        df_train[col] = np.zeros([df_train.shape[0], 1])\n",
    "\n",
    "    missing_cols = set(df_train.columns) - set(df_test.columns)\n",
    "    for col in missing_cols:\n",
    "        print(df_train.shape, df_test.shape)\n",
    "        df_test[col] = np.zeros([df_test.shape[0], 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sex', 'Age', 'SibSp', 'Parch', 'Title_Mr0', 'Title_Mr50', 'Title_Mrs', 'Title_Ms', 'Age_bin_Kid', 'Age_bin_Teenager', 'Age_bin_Adult', 'FamilySize', 'Family_bin_SmallFamily', 'Family_bin_BigFamily', 'Family_bin_Team', 'Fare_bin_Median', 'Fare_bin_Average', 'Fare_bin_High', 'Em_C', 'Em_Q', 'Em_S', 'Cabin_A', 'Cabin_B', 'Cabin_C', 'Cabin_D', 'Cabin_E', 'Cabin_F', 'Cabin_G', 'Cabin_T', 'Cabin_X', 'Mother', 'Father', 'Daughter', 'Son', 'Orphan', 'RichWoman', 'MiddleClassWoman', 'PoorWoman', 'RichMan', 'MiddleClassMan', 'PoorMan', 'RichGirl', 'MiddleClassGirl', 'PoorGirl', 'RichBoy', 'MiddleClassBoy', 'PoorBoy', 'Pclass_2', 'Pclass_3'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sex', 'Age', 'SibSp', 'Parch', 'Title_Mr0', 'Title_Mr50', 'Title_Mrs', 'Title_Ms', 'Age_bin_Kid', 'Age_bin_Teenager', 'Age_bin_Adult', 'FamilySize', 'Family_bin_SmallFamily', 'Family_bin_BigFamily', 'Family_bin_Team', 'Fare_bin_Median', 'Fare_bin_Average', 'Fare_bin_High', 'Em_C', 'Em_Q', 'Em_S', 'Cabin_A', 'Cabin_B', 'Cabin_C', 'Cabin_D', 'Cabin_E', 'Cabin_F', 'Cabin_G', 'Cabin_X', 'Mother', 'Father', 'Daughter', 'Son', 'Orphan', 'RichWoman', 'MiddleClassWoman', 'PoorWoman', 'RichMan', 'MiddleClassMan', 'PoorMan', 'RichGirl', 'MiddleClassGirl', 'PoorGirl', 'RichBoy', 'MiddleClassBoy', 'PoorBoy', 'Pclass_2', 'Pclass_3', 'Cabin_T'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original\n",
      "##################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jim\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\jim\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\jim\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\jim\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\jim\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilayer Perceptron provided 0.7891579655464889 accuracy at validation stage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jim\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only size-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-07dc7071f11a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Original'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'##################################'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodels_perform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\AI\\CI\\project\\titanic_survival\\model\\models.py\u001b[0m in \u001b[0;36mmodels_perform\u001b[1;34m(data, data_labels, test, test_labels)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m# Support Vector Machine\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[1;31m# Random Forest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_forest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\AI\\CI\\project\\titanic_survival\\model\\svm.py\u001b[0m in \u001b[0;36msvm\u001b[1;34m(data, labels, train_fidx, validation_fidx)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mfolds_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_fidx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mtrf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0msvc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mprediction_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalidation_fidx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "print('Original')\n",
    "print('##################################')\n",
    "models_perform(df_train, labels, df_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
